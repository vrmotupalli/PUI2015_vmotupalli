{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pylab as pl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "\n",
    "#plus importing scipy.stats\n",
    "import scipy.stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate the distribution\n",
    "dist_n = np.random.randn(1000)\n",
    "\n",
    "#test ad and ks. those are easy\n",
    "print \"normal on normal\", scipy.stats.kstest(dist_n,'norm')\n",
    "print \"normal on normal\", scipy.stats.anderson(dist_n, dist='norm')\n",
    "print \"\" \n",
    "\n",
    "dist_p = np.random.poisson(1, 1000)\n",
    "\n",
    "print \"poisson on normal\", scipy.stats.kstest(dist_p,'norm')\n",
    "print \"poisson on normal\", scipy.stats.anderson(dist_p, dist='norm')\n",
    "\n",
    "threshold = scipy.stats.anderson(dist_n, dist='norm')[1][scipy.stats.anderson(dist_n, dist='norm')[2]==[1.0]]\n",
    "print threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "distpdf_n, mybins_n, = np.histogram(dist_n, density=True)\n",
    "distpdf_b, mybins_b, = np.histogram(dist_b, density=True)\n",
    "#notice the extra comma on the left side of the '=' sign: that tells numpy take the first two values returned, and throw away the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the bin centers\n",
    "bincenters_n = mybins_n[:-1] + 0.5*(mybins_n[1] - mybins_n[0])\n",
    "bincenters_b = mybins_b[:-1] + 0.5*(mybins_b[1] - mybins_b[0])\n",
    "print \"normal on normal\", scipy.stats.entropy(distpdf_n, scipy.stats.norm.pdf(bincenters_n))  \n",
    "print \"poisson on normal\", scipy.stats.entropy(distpdf_b, scipy.stats.norm.pdf(bincenters_b)) \n",
    "\n",
    "#you can interpret this as a distance: it increases as the distributions diverge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to store the data i am generating an empty array of the size of the values of n i want to test. i do that with np.zeros which takes the length of the array as argument, and the data type as optional argument, but default is float, which is fine by me, so i do not need any argument other then the lenght \n",
    "narray = range(1,50,1)\n",
    "ks_b = np.zeros(len(narray))\n",
    "ad_b = np.zeros(len(narray))\n",
    "kl_b = np.zeros(len(narray))\n",
    "chi2_b = np.zeros(len(narray))\n",
    "\n",
    "\n",
    "def mynorm (x, mu, var):\n",
    "    return scipy.stats.norm.cdf(x, loc=mu, scale=var)\n",
    "\n",
    "#then i put the tests in a for loop so that i can generate a distribution for given parameters once, \n",
    "#and run all tests against it\n",
    "#now the valus that i want to plot depends on how i intend to describe the plot, and viceversa. \n",
    "\n",
    "#here is one way to plot it, knowing the values i get for the tests when \n",
    "#i throw in a poisson distribution with low l and compare it with a gaussian and \n",
    "#assuming that that is a vary bad match\n",
    "p=0.5\n",
    "for i,n in enumerate(narray):\n",
    "    p=0.1 #parameter for the binomial, my arbitrary choice\n",
    "    #generate the distribution\n",
    "    dist = np.random.binomial(n, p, 1000)\n",
    "    #run the tests. \n",
    " \n",
    "    ks_b[i] = scipy.stats.kstest(dist, mynorm, args=(n*p, n*p*(1.0-p)))[0]\n",
    "    ad_b[i] = scipy.stats.anderson(dist, dist='norm')[0]\n",
    "    \n",
    "    \n",
    "    # for KL and Pearson's chisq I have to simulate the normal distribution as well\n",
    "    mybins=np.linspace(min(dist),max(dist), 10) \n",
    "    bincenters = mybins[:-1]+0.5*(mybins[1]-mybins[0])\n",
    "\n",
    "    #when i was coding this up something was wrong. i put some plots in to figure out what... just so you know.\n",
    "    #if i%10 == 0: \n",
    "    #    print n\n",
    "    #    pl.figure()\n",
    "    #    pl.hist(dist, bins=mybins)\n",
    "    #    pl.plot(bincenters, 1000*scipy.stats.norm.pdf(bincenters, loc=n*p, scale=n*p*(1-p)))\n",
    "    kl_b [i] =  scipy.stats.entropy(np.histogram(dist, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p, scale=n*p*(1.0-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize = (15,5))\n",
    "fig.add_subplot(131)\n",
    "pl.plot(narray, ks_b, label='KS')\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(132)\n",
    "pl.plot(narray, ad_b,  label='AD')\n",
    "pl.plot([narray[0], narray[-1]],[threshold, threshold])\n",
    "pl.plot()\n",
    "pl.plot()\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(133)\n",
    "pl.plot(narray, kl_b, label='K-L ')\n",
    "\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to store the data i am generating an empty array of the size of the values of n i want to test. i do that with np.zeros which takes the length of the array as argument, and the data type as optional argument, but default is float, which is fine by me, so i do not need any argument other then the lenght \n",
    "narray = range(1,50,1)\n",
    "ks_b = np.zeros(len(narray))\n",
    "ad_b = np.zeros(len(narray))\n",
    "kl_b = np.zeros(len(narray))\n",
    "chi2_b = np.zeros(len(narray))\n",
    "\n",
    "\n",
    "#then i put the tests in a for loop so that i can generate a distribution for given parameters once, \n",
    "#and run all tests against it\n",
    "#now the valus that i want to plot depends on how i intend to describe the plot, and viceversa. \n",
    "\n",
    "#here is one way to plot it, knowing the values i get for the tests when \n",
    "#i throw in a poisson distribution with low l and compare it with a gaussian and \n",
    "#assuming that that is a vary bad match\n",
    "\n",
    "for i,n in enumerate(narray):\n",
    "    p=0.1 #parameter for the binomial, my arbitrary choice\n",
    "    #generate the distribution\n",
    "    dist = np.random.poisson(n, 1000)\n",
    "    #run the tests. \n",
    "    ks_b[i] = scipy.stats.kstest(dist, mynorm, args=(n, n))[0]\n",
    "    ad_b[i] = scipy.stats.anderson(dist, dist='norm')[0]\n",
    "    \n",
    "        \n",
    "    # for KL and Pearson's chisq I have to simulate the normal distribution as well\n",
    "    mybins = np.linspace(min(dist),max(dist), 10) \n",
    "    bincenters = mybins[:-1]+0.5*(mybins[1]-mybins[0])\n",
    " \n",
    "    kl_b [i] =  scipy.stats.entropy(np.histogram(dist, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p, scale=n*p*(1.0-p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = pl.figure(figsize = (15,5))\n",
    "fig.add_subplot(131)\n",
    "pl.plot(narray, ks_b, label='KS')\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(132)\n",
    "pl.plot(narray, ad_b,  label='AD')\n",
    "pl.plot([narray[0], narray[-1]],[threshold, threshold])\n",
    "pl.plot()\n",
    "pl.plot()\n",
    "pl.legend()\n",
    "\n",
    "fig.add_subplot(133)\n",
    "pl.plot(narray, kl_b, label='K-L ')\n",
    "\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#to store the data i am generating an empty array of the size of the values of n i want to test. i do that with np.zeros which takes the length of the array as argument, and the data type as optional argument, but default is float, which is fine by me, so i do not need any argument other then the lenght \n",
    "narray = range(1,50,1)\n",
    "ks_b = np.zeros(len(narray))\n",
    "ad_b = np.zeros(len(narray))\n",
    "kl_b = np.zeros(len(narray))\n",
    "chi2_b = np.zeros(len(narray))\n",
    "\n",
    "\n",
    "#then i put the tests in a for loop so that i can generate a distribution for given parameters once, \n",
    "#and run all tests against it\n",
    "#now the valus that i want to plot depends on how i intend to describe the plot, and viceversa. \n",
    "\n",
    "#here is one way to plot it, knowing the values i get for the tests when \n",
    "#i throw in a poisson distribution with low l and compare it with a gaussian and \n",
    "#assuming that that is a vary bad match\n",
    "\n",
    "for i,n in enumerate(narray):\n",
    "    p=0.1 #parameter for the binomial, my arbitrary choice\n",
    "    #generate the distribution\n",
    "    dist = np.random.poisson(n, 1000)\n",
    "    #run the tests. \n",
    "    ks_b[i] = scipy.stats.kstest(dist, mynorm, args=(n, n))[0]\n",
    "    ad_b[i] = scipy.stats.anderson(dist, dist='norm')[0]\n",
    "    \n",
    "        \n",
    "    # for KL and Pearson's chisq I have to simulate the normal distribution as well\n",
    "    mybins = np.linspace(min(dist),max(dist), 10) \n",
    "    bincenters = mybins[:-1]+0.5*(mybins[1]-mybins[0])\n",
    " \n",
    "    kl_b [i] =  scipy.stats.entropy(np.histogram(dist, bins=mybins)[0], scipy.stats.norm.pdf(bincenters, loc=n*p, scale=n*p*(1.0-p)))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
